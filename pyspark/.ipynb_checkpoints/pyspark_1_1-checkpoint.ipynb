{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dfd178d-6985-4c76-be60-49169a81d209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n",
      "C:\\Program Files\\Python313\\python.exe\n",
      "C:\\python311\\python.exe\n",
      "C:\\Users\\saad\\AppData\\Local\\Programs\\Python\\Python310\\python.exe\n",
      "C:\\Users\\saad\\AppData\\Local\\Microsoft\\WindowsApps\\python.exe\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")\n",
    "!where python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a645cfdc-2a33-41a2-87ec-1cf604168043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed47c449-5e90-4e33-8c12-9d70dd5fea49",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_pyspark \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mcsv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124msaad\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mpycharmWorkspace\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124msaadMachineLearning\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdatasets\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdiabetes.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv(\"C:\\\\saad\\\\pycharmWorkspace\\\\saadMachineLearning\\\\datasets\\\\diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "134c4e80-ccac-471f-9274-d3366ae9a4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "338889a9-87c1-4471-be7c-2aa8c203190b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(r\"C:\\Program Files\\Python313\\Lib\\site-packages\\pyspark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7fbfcc1-d568-4550-bb8d-6c09e5104965",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_pyspark \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mcsv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124msaad\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mpycharmWorkspace\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124msaadMachineLearning\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdatasets\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdiabetes.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv(\"C:\\\\saad\\\\pycharmWorkspace\\\\saadMachineLearning\\\\datasets\\\\diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a03703e-589f-4233-abff-0ab5cddaf343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyspark in c:\\users\\saad\\appdata\\roaming\\python\\python313\\site-packages (4.0.1)\n",
      "Requirement already satisfied: py4j==0.10.9.9 in c:\\users\\saad\\appdata\\roaming\\python\\python313\\site-packages (from pyspark) (0.10.9.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60b40e73-7bb5-435c-a3a1-e11235b2fb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\python311\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "295ef771-55b2-4457-af66-74e4c00adc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "findspark.init(r\"C:\\python311\\Lib\\site-packages\\pyspark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "047c7ea7-4abf-4846-ba97-5543164f143e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_pyspark \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mcsv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124msaad\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mpycharmWorkspace\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124msaadMachineLearning\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdatasets\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdiabetes.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv(\"C:\\\\saad\\\\pycharmWorkspace\\\\saadMachineLearning\\\\datasets\\\\diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a896e649-e5a2-48b2-94fb-da16da61aa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5c64e59-8851-4b5e-a29a-bb36e7c48cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Ratios').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05bff59d-c176-40a1-833b-af7cc038e78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv(\"C:\\\\saad\\\\pycharmWorkspace\\\\saadMachineLearning\\\\datasets\\\\diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "827a2efd-0627-464a-b3da-c380f7ec4ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+-------------+-------+----+--------------------+---+-------+\n",
      "|        _c0|    _c1|          _c2|          _c3|    _c4| _c5|                 _c6|_c7|    _c8|\n",
      "+-----------+-------+-------------+-------------+-------+----+--------------------+---+-------+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeF...|Age|Outcome|\n",
      "|          6|    148|           72|           35|      0|33.6|               0.627| 50|      1|\n",
      "|          1|     85|           66|           29|      0|26.6|               0.351| 31|      0|\n",
      "|          8|    183|           64|            0|      0|23.3|               0.672| 32|      1|\n",
      "|          1|     89|           66|           23|     94|28.1|               0.167| 21|      0|\n",
      "+-----------+-------+-------------+-------------+-------+----+--------------------+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7901acfb-1a55-48dd-823e-80388a130fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
